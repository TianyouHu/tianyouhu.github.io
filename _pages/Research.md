---
layout: archive
title: ""
permalink: /research/
author_profile: true
---
Vision Based Exploration in Fully Unknown Environment
====
I worked in Professor [Yiannis Kantaros'](https://engineering.wustl.edu/faculty/Yiannis-Kantaros.html) lab at WashU since August 2022.I applied autonomous exploration algorithm on our Turtlebot3 Waffle Pi robot by combining RRT naviation algorithm and Karto SLAM method. Besides this, I applied YOLOv7 on our robot for object detection and depth estimation to obtain distance of specific object. My current work is combing laserscan and YOLO info to obtain position of pedestrian. The next step is predicting pedestrians trajectory based on their behavior.

Please check these demo videos. 

Object detection and autonomous navigation on pad (kinda bumpy)
<iframe width="560" height="315" src="https://www.youtube.com/embed/ixDVWG9pUJ4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

not on pad
<iframe width="560" height="315" src="https://www.youtube.com/embed/ICd1tCqf2rU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

depth estimation
<iframe width="560" height="315" src="https://www.youtube.com/embed/qh8bAIE5-mA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

test environment of depth estimation
<iframe width="560" height="315" src="https://www.youtube.com/embed/OoZ20Jg31_E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>



